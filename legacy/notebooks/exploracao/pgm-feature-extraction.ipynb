{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esdras-daniel/Documentos/Python/PGM-DataAnalysis/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-13 09:50:22.980238: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739451022.998703   11534 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739451023.004049   11534 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-13 09:50:23.023627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from gensim.models import Word2Vec, FastText\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 - Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 104]\n",
      "[nltk_data]     Connection reset by peer>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "def preprocessar_texto(text):\n",
    "    \"\"\"Limpeza, remoção de stopwords e lematização\"\"\"\n",
    "    text = re.sub(r\"\\b\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2}\\b\", \"[CPF]\", text)\n",
    "    text = re.sub(r\"\\b\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}\\b\", \"[CNPJ]\", text)\n",
    "    text = re.sub(r\"\\b\\d{2}\\)?\\s?\\d{4,5}-?\\d{4}\\b\", \"[TELEFONE]\", text)\n",
    "    text = re.sub(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", \"[EMAIL]\", text)\n",
    "    text = re.sub(r'\\d{7}-\\d{2}\\.\\d{4}\\.\\d\\.\\d{2}\\.\\d{4}', '[PROCESSO]', text)\n",
    "    text = re.sub(r'\\d{5}-?\\d{3}', '[CEP]', text)\n",
    "    \n",
    "    #text = text.lower()\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and token.text not in stopwords and len(token.text) > 2]\n",
    "\n",
    "    return \" \".join(tokens).lower()\n",
    "\n",
    "def representacao_texto(metodo: str, df: pd.DataFrame):\n",
    "    if metodo == \"TF-IDF\":\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, min_df=0.005, max_df=0.4)\n",
    "        X = vectorizer.fit_transform(df[\"texto_limpo\"]).toarray()\n",
    "    \n",
    "    #elif metodo == \"Word2Vec\":\n",
    "    #    model_w2v = Word2Vec(sentences=[text.split() for text in df[\"texto_limpo\"]], vector_size=100, window=5, min_count=1)\n",
    "    #    X = np.array([np.mean([model_w2v.wv[word] for word in text.split() if word in model_w2v.wv] or [np.zeros(100)], axis=0) for text in df[\"texto_limpo\"]])\n",
    "\n",
    "    #elif metodo == \"FastText\":\n",
    "    #    model_ft = FastText(sentences=[text.split() for text in df[\"texto_limpo\"]], vector_size=100, window=5, min_count=1)\n",
    "    #    X = np.array([np.mean([model_ft.wv[word] for word in text.split() if word in model_ft.wv] or [np.zeros(100)], axis=0) for text in df[\"texto_limpo\"]])\n",
    "\n",
    "    elif metodo == \"BERT\":\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "        model_bert = BertModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "\n",
    "        def embed_bert(text):\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            outputs = model_bert(**inputs)\n",
    "            return outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "\n",
    "        X = np.vstack([embed_bert(text) for text in df[\"texto_limpo\"]])\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teorTexto</th>\n",
       "      <th>setorDestino</th>\n",
       "      <th>tipoAviso</th>\n",
       "      <th>orgaoJulgador</th>\n",
       "      <th>assuntos</th>\n",
       "      <th>documentos</th>\n",
       "      <th>anexos</th>\n",
       "      <th>classeProcesso</th>\n",
       "      <th>qtd_sentenca</th>\n",
       "      <th>qtd_acordao</th>\n",
       "      <th>qtd_transito_julgado</th>\n",
       "      <th>novoSetorDestino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PODER JUDICIÁRIO DO ESTADO DO RIO GRANDE DO NO...</td>\n",
       "      <td>APOIO FISCAL</td>\n",
       "      <td>IntimaÆo</td>\n",
       "      <td>5ª Vara de Execução Fiscal e Tributária de Natal</td>\n",
       "      <td>5952</td>\n",
       "      <td>Despacho;Petição;Intimação;Diligência;Penhora;...</td>\n",
       "      <td>0243943-10.2007.8.20.0001 Ext DA;Endereço da e...</td>\n",
       "      <td>1116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>APOIO FISCAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PODER JUDICIÁRIO DO ESTADO DO RIO GRANDE DO NO...</td>\n",
       "      <td>APOIO FISCAL</td>\n",
       "      <td>IntimaÆo</td>\n",
       "      <td>4ª Vara de Execução Fiscal e Tributária de Natal</td>\n",
       "      <td>10536;5952</td>\n",
       "      <td>Certidão Trânsito em Julgado;Sentença;Petição ...</td>\n",
       "      <td>0865696-23.2018.8.20.5001 Ext DA;Rcda - extrat...</td>\n",
       "      <td>1116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>APOIO FISCAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PODER JUDICIÁRIO DO ESTADO DO RIO GRANDE DO NO...</td>\n",
       "      <td>APOIO FISCAL</td>\n",
       "      <td>IntimaÆo</td>\n",
       "      <td>4ª Vara de Execução Fiscal e Tributária de Natal</td>\n",
       "      <td>5951</td>\n",
       "      <td>Decisão;Diligência;Mandado;Despacho;Certidão;D...</td>\n",
       "      <td>0508032-92.2006;0508032-92.2006 - EXT;0508032-...</td>\n",
       "      <td>1116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>APOIO FISCAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           teorTexto  setorDestino  tipoAviso  \\\n",
       "0  PODER JUDICIÁRIO DO ESTADO DO RIO GRANDE DO NO...  APOIO FISCAL  IntimaÆo   \n",
       "1  PODER JUDICIÁRIO DO ESTADO DO RIO GRANDE DO NO...  APOIO FISCAL  IntimaÆo   \n",
       "2  PODER JUDICIÁRIO DO ESTADO DO RIO GRANDE DO NO...  APOIO FISCAL  IntimaÆo   \n",
       "\n",
       "                                      orgaoJulgador    assuntos  \\\n",
       "0  5ª Vara de Execução Fiscal e Tributária de Natal        5952   \n",
       "1  4ª Vara de Execução Fiscal e Tributária de Natal  10536;5952   \n",
       "2  4ª Vara de Execução Fiscal e Tributária de Natal        5951   \n",
       "\n",
       "                                          documentos  \\\n",
       "0  Despacho;Petição;Intimação;Diligência;Penhora;...   \n",
       "1  Certidão Trânsito em Julgado;Sentença;Petição ...   \n",
       "2  Decisão;Diligência;Mandado;Despacho;Certidão;D...   \n",
       "\n",
       "                                              anexos  classeProcesso  \\\n",
       "0  0243943-10.2007.8.20.0001 Ext DA;Endereço da e...            1116   \n",
       "1  0865696-23.2018.8.20.5001 Ext DA;Rcda - extrat...            1116   \n",
       "2  0508032-92.2006;0508032-92.2006 - EXT;0508032-...            1116   \n",
       "\n",
       "   qtd_sentenca  qtd_acordao  qtd_transito_julgado novoSetorDestino  \n",
       "0             0            0                     0     APOIO FISCAL  \n",
       "1             1            0                     1     APOIO FISCAL  \n",
       "2             0            0                     0     APOIO FISCAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/pgm-dataset-v6-clean.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Aplicando pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6327/6327 [06:35<00:00, 16.01it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df['texto_limpo'] = df['teorTexto'].progress_apply(preprocessar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Seleção da Representação do Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = representacao_texto(metodo='TF-IDF', df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_bert \u001b[38;5;241m=\u001b[39m \u001b[43mrepresentacao_texto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetodo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBERT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m, in \u001b[0;36mrepresentacao_texto\u001b[0;34m(metodo, df)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metodo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     36\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuralmind/bert-base-portuguese-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     model_bert \u001b[38;5;241m=\u001b[39m \u001b[43mBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuralmind/bert-base-portuguese-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_bert\u001b[39m(text):\n\u001b[1;32m     40\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/Python/PGM-DataAnalysis/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1690\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1690\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/Python/PGM-DataAnalysis/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1678\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1676\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "X_bert = representacao_texto(metodo='BERT', df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
